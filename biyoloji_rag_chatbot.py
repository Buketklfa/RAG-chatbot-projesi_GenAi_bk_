# -*- coding: utf-8 -*-
"""biyoloji_rag_chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUlHP932_7hyGG-cNjJ_Sc7-tOO2WIIE
"""

# # 🧬 Khan Academy Türkçe Biyoloji RAG Chatbot
#
# Bu notebook, RAG (Retrieval Augmented Generation) mimarisini kullanarak Khan Academy'nin Türkçe biyoloji içeriklerinden filtrelenmiş verilerle bir chatbot oluşturur.
#
# **Teknik Özellikler:**
# - **Generation Model:** Gemini 2.5 Flash
# - **Embedding Model:** sentence-transformers/distiluse-base-multilingual-cased-v2 (Hugging Face)
# - **Vector DB:** Chroma
# - **RAG Framework:** LangChain
# - **Data Source:** ysdede/khanacademy-turkish
# - **Hata Düzeltme:** Dinamik sütun adı tespiti ve bellek yönetimi (GPU kullanımı önerilir).

# ==============================================================================
# BÖLÜM 1: KURULUM VE API ANAHTARI AYARLARI
# ==============================================================================

print("1/4: Kütüphane kurulumları ve API anahtarı ayarlanıyor...")

# Bağımlılık sorunlarını (özellikle torch/datasets[audio]) gidermek için zorunlu kurulumlar
!pip install -q torch
!pip install -q datasets[audio] langchain chromadb sentence-transformers langchain-huggingface google-genai langchain-google-genai langchain-community

# Gerekli kütüphane içe aktarımları
import os
import sys
import shutil
import gc # Bellek temizliği için
from getpass import getpass
from datasets import load_dataset
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI

# --- SABİTLER ---
LLM_MODEL_NAME = "gemini-2.5-flash"
EMBEDDING_MODEL_NAME = "sentence-transformers/distiluse-base-multilingual-cased-v2"
CHROMA_DB_DIR = "./chroma_db_biyoloji_st"
DATASET_NAME = "ysdede/khanacademy-turkish"
BIYOLOJI_KEYWORDS = ["biyoloji", "hücre", "DNA", "RNA", "genetik", "evrim", "fotosentez", "solunum", "mitoz", "mayoz", "protein", "enzim", "canlı", "organ"]
MAX_DOCUMENTS = 100 # Bellek sorununu hafifletmek için geçici üst sınır. İstenirse kaldırılabilir.

# --- API Anahtarını Ayarlama ---
if "GEMINI_API_KEY" not in os.environ:
    print("\n--- API ANAHTARI GEREKLİ ---")
    api_key = getpass("Lütfen Gemini API Anahtarınızı buraya yapıştırıp ENTER'a basın: ")
    os.environ["GEMINI_API_KEY"] = api_key

if not os.getenv("GEMINI_API_KEY"):
    print("❌ HATA: API Anahtarı yüklenemedi. Program sonlandırılıyor.")
    sys.exit(1)

print("✅ Kurulumlar ve API Anahtarı Hazır.")


# ==============================================================================
# BÖLÜM 2: VERİ YÜKLEME, SÜTUN TESPİTİ VE FİLTRELEME (Dinamik Düzeltme)
# ==============================================================================

def get_text_column_name(dataset_name):
    """Veri setindeki metin içeriğini içeren sütun adını dinamik olarak tespit eder."""
    print("📢 Veri seti özelliklerini (sütun adlarını) kontrol ediliyor...")
    try:
        # Şemayı görmek için veri setinin bir kısmını yükle
        dataset_info = load_dataset(dataset_name, split="train", streaming=False)
        available_columns = list(dataset_info.features.keys())

        print(f"   -> Mevcut sütunlar: {available_columns}")

        # Yaygın sütun adlarını kontrol et:
        if 'content' in available_columns:
            return 'content'
        elif 'text' in available_columns:
            return 'text'
        elif 'transcript' in available_columns:
            return 'transcript'
        elif 'transcription' in available_columns: # Added 'transcription'
            return 'transcription'
        else:
            print("\n❌ HATA: Metin içeriği için uygun sütun ('content', 'text', 'transcript', 'transcription') bulunamadı.")
            sys.exit(1)

    except Exception as e:
        print(f"\n❌ Kritik Hata: Veri seti özellikleri yüklenemedi: {e}")
        sys.exit(1)

def filter_biyoloji(example, text_column_name):
    """Verilen sütun adına göre biyoloji anahtar kelimelerini filtreler."""
    text_content = example.get(text_column_name, '')
    if not text_content:
        return False
    return any(keyword in str(text_content).lower() for keyword in BIYOLOJI_KEYWORDS)

def load_and_prepare_data():
    """Veri setini yükler, doğru sütun adı ile filtreler ve Document listesi döndürür."""
    print(f"\n2/4: {DATASET_NAME} veri seti yükleniyor ve filtreleniyor...")

    # Dinamik sütun adını tespit et
    TEXT_COLUMN_NAME = get_text_column_name(DATASET_NAME)
    print(f"✅ Filtreleme için '{TEXT_COLUMN_NAME}' sütunu belirlendi.")

    # Veriyi streaming modunda yükleme
    dataset = load_dataset(DATASET_NAME, split="train", streaming=True)

    documents = []
    biyoloji_kayit_sayisi = 0

    print(f"   -> Filtreleme Başlandı. (Maksimum {MAX_DOCUMENTS} kayıt alınacak)")

    # Veri akışını tüketerek filtreleme yapıyoruz.
    for item in dataset:
        if biyoloji_kayit_sayisi >= MAX_DOCUMENTS:
            print(f"   -> Maksimum kayıt sınırına ({MAX_DOCUMENTS}) ulaşıldı. İşlem durduruluyor.")
            break

        if filter_biyoloji(item, TEXT_COLUMN_NAME):
            content = item.get(TEXT_COLUMN_NAME)
            if content:
                documents.append(
                    Document(
                        page_content=str(content),
                        metadata={"source": "Khan Academy Biyoloji"}
                    )
                )
                biyoloji_kayit_sayisi += 1
                if biyoloji_kayit_sayisi % 100 == 0: # Changed print frequency
                    print(f"   ... {biyoloji_kayit_sayisi} biyoloji kaydı işlendi.")

    print(f"\n✅ Filtreleme tamamlandı. Toplam biyoloji belgesi: {len(documents)}")
    return documents


# ==============================================================================
# BÖLÜM 3: CHUNKING, EMBEDDING VE VECTOR DB OLUŞTURMA
# ==============================================================================

def create_vector_store(documents):
    """Veri parçacıklarını oluşturur ve ChromaDB'de vektörleştirir."""
    print(f"\n3/4: Chunking ve Vektör Veritabanı oluşturuluyor...")

    # 1. Metin Bölme (RecursiveCharacterTextSplitter)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ".", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"   -> Toplam {len(documents)} belgeden {len(chunks)} parça oluşturuldu.")

    # 2. Embedding Modeli (Sentence Transformer)
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'}
    )

    # 3. Vector Store (ChromaDB) Oluşturma
    if os.path.exists(CHROMA_DB_DIR):
        shutil.rmtree(CHROMA_DB_DIR)

    print("   -> Vektörleştirme işlemi başlıyor. (GPU tavsiye edilir)")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=CHROMA_DB_DIR
    )
    vectorstore.persist()
    print(f"✅ Vektör Veritabanı başarıyla oluşturuldu.")

    # Bellek Yönetimi: Büyük listeleri siliyoruz.
    if 'documents' in locals():
        del documents
    if 'chunks' in locals():
        del chunks
    gc.collect()
    print("🧹 Bellek temizliği yapıldı.")
    return vectorstore


# ==============================================================================
# BÖLÜM 4: RAG ZİNCİRİ VE TEST
# ==============================================================================

def create_rag_chain(vectorstore):
    """LLM'i Prompt Template ile birleştirerek RetrievalQA zincirini oluşturur."""
    print("\n4/4: RAG Zinciri (RetrievalQA) oluşturuluyor...")

    llm = ChatGoogleGenerativeAI(model=LLM_MODEL_NAME, temperature=0.2)

    # Prompt Şablonu: Modelin rolünü ve kısıtlamasını tanımlar.
    template = """Sen, yalnızca sağlanan bağ bağlamdaki Biyoloji sorularını yanıtlamak üzere tasarlanmış, çok bilgili bir uzmansın.
Eğer soru BİYOLOJİ ile ilgili değilse veya cevabı sağlanan bağ bağlamda bulamıyorsan, kibarca 'Üzgünüm, sadece Khan Academy'den filtrelenmiş biyoloji sorularına ve eldeki bilgilere dayanarak cevap verebilirim.' diye yanıtla.
Cevaplarını her zaman Türkçe ve anlaşılır bir dille ver.

Bağ bağlam:
{context}

Soru: {question}
Cevap:"""

    RAG_PROMPT_TEMPLATE = PromptTemplate(
        input_variables=["context", "question"],
        template=template,
    )

    # Retriever: En benzer 3 parçayı çeker.
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": RAG_PROMPT_TEMPLATE},
        return_source_documents=True
    )

    print(f"✅ RAG Zinciri ({LLM_MODEL_NAME}) hazır.")
    return qa_chain


def run_tests(qa_chain):
    """Chatbot'u denemek için örnek soruları çalıştırır."""

    def ask_biyoloji_chatbot(question):
        print(f"\n" + "—"*70)
        print(f">> SORU: {question}")

        result = qa_chain.invoke({"query": question})

        sources = set([doc.metadata.get('source', 'Bilinmeyen Kaynak') for doc in result['source_documents']])

        print(f"\n>> CHATBOT CEVABI:\n{result['result']}")
        print(f"\n>> KULLANILAN KAYNAKLAR: {', '.join(sources)}")
        print("—"*70)
        return result

    print("\n" + "="*70)
    print("🧬 CHATBOT DENEME TESTLERİ BAŞLIYOR")
    print("="*70)

    # Test 1: İstek Sorusu (DNA nedir?)
    ask_biyoloji_chatbot("DNA nedir?")

    # Test 2: Kompleks Biyoloji Sorusu
    ask_biyoloji_chatbot("Mitokondri hangi işlevi görür ve neden hücrenin güç santrali olarak adlandırılır?")

    # Test 3: Biyoloji Dışı Soru (Kısıtlama Kontrolü)
    ask_biyoloji_chatbot("Python ile yapay zeka nasıl yapılır?")

    print("✅ Tüm testler tamamlandı. Chatbot kullanıma hazırdır.")


# ==============================================================================
# ANA ÇALIŞMA BLOĞU
# ==============================================================================

if __name__ == "__main__":

    try:
        # 1. Veri setini yükle ve hazırla
        documents = load_and_prepare_data()

        if not documents:
            print("\n❌ HATA: Biyoloji içeriği bulunamadı. Program sonlandırılıyor.")
            sys.exit(1)

        # 2. Vektör veritabanını oluştur
        vectorstore = create_vector_store(documents)

        # 3. RAG zincirini oluştur
        qa_chain = create_rag_chain(vectorstore)

        # 4. Testleri çalıştır
        run_tests(qa_chain)

    except Exception as e:
        print(f"\nKRİTİK HATA: Proje çalışırken beklenmeyen bir hata oluştu: {e}")
        # Programı sonlandır.